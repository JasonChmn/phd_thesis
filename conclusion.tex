\chapter{Conclusion}
\label{sec:conclusion}


% ====== Cheminement argumentaire. Reprenez votre question de recherche, expliquez les pas que vous avez faits pour y répondre à travers les différents chapitres. Grâce à ce résumé, on doit bien sentir comment les différentes parties de la thèse s’articulent et « tiennent » bien ensemble, pourquoi le cheminement est cohérent.

This thesis explored a new approach for \textbf{legged character navigation} in complex terrains. At the core of our research dominated the question of the \textbf{feasibility}: \textit{How to plan feasible paths by our robot?}

Our work is part of the Loco3D framework whose architecture divides the difficult locomotion problem into three sequentially solved sub-problems. First is the planning of the robot \textbf{guide path} to navigate the terrain (P1), second is the \textbf{contact planning} along this guide (P2), and third is the whole body movement performing these contacts (P3).
Our research thus focused on the critical problem at top of the chain of this architecture, that is the feasibility of (P1) by (P2).
We progressed one step beyond the previous work \cite{RB-PRM} that introduced the \textbf{reachability} condition, necessary but insufficient to fully capture the contact planner capabilities (P2) and the closely related concept of terrain \textbf{traversability}.

\hfill \break

\noindent\textbf{Research contribution.}\\

The main contribution of this thesis is a \textbf{reinforcement learning} local steering method, called LEAS. We first demonstrated its navigation skills in complex environments, while being subject to collision-avoidance and reachability constraints, hence already providing a ready-to-use navigation method.
Then we have shown how our solution can grasp both concepts of feasibility and traversability through trial and error using a contact planner as a validation oracle.
Our method was learned with three different contact planners of our team, for which LEAS learned how to generate feasible guide paths, hence increasing their contact planning success rate or reducing their computation time.

%\hfill \break

% ====== Reponse a la question de recherche. Mettez en avant votre position de chercheur. C’est difficile car cela implique une prise de risque de votre part : vous devez exprimer un point de vue original, c’est-à-dire peut-être différent de ce qui s’était fait ou dit avant. Cette originalité est une force, du moment que vous avez des arguments basés sur des données pour soutenir votre position.

% Ma question de recherche: How to learn by reinforcement a navigation task for a better contact planning feasibility?
% How to generate feasible guide paths?
Our steering method answers our research question: \textit{How to learn by reinforcement a navigation task for better contact planning feasibility?}
We have explored the answers with our three different contact planning strategies.
Our results demonstrated that navigating with only a simple local height map of the terrain was sufficient to approximate a part, if not all, of their feasibility space.
Even despite the mixed results on SL1M, we observed that our steering method was still able to find some strategies to increase its success rate within the limit of its controls.
Interpreting the strategies learned by LEAS is promising to have further insight into our contact planners and improve them.

% ====== Limitations de ma recherche. Il y a toujours des points que vous avez moins bien traités ou que vous avez décidé de ne pas traiter. Si cela vous semble important rappelez pourquoi, mais ne soyez pas négatif envers votre travail.

\hfill \break

\noindent\textbf{Limitations of the study.}\\

This thesis employed the contact planners as a black box with their original formulation. Consequently, several implementations and parameter choices were made relative to their connection to the guide path.

% Acyclic => La question de la discretisation du guide qu'on a pas pu faire à cause des temps de calcul. Après plus d'optimisation du côté du guide + du contact planner, ça pourrait être possible.
On the sampling-based planner (Chapter \ref{sec:CP-SB}), we fixed a desired configuration step along the guide to cope with its relatively high computation time. 
Consequently, we did not investigate the guide discretization as done with the MIP contact planner.
At the moment, the contact planner generates many key contact posture along the guide, that is then filtered by manually designed heuristics. 
However, these heuristics often present unpredictable performance regarding the contact plan quality.
That is why directly adopting a sufficiently high discretization step would be desirable to avoid using such heuristics.

% MIP => Gurobi est trop fort. On a vu qu'avec le guide il l'était encore plus, 120 pas en 400ms c'est quand même super rapide. On aurait bien aimé testé avec d'autres MIP solvers aussi, voir si les résultats étaient les mêmes. Au final là on a juste trouvé une approximate d'un nombre de pas max pour chaque trajectoire.
The MIP contact planner (Section \ref{sub:mip:mip}) was solved (too) efficiently by the commercial solver Gurobi. Consequently, we could not accurately analyze the impact of the combinatorics reduction on the problem complexity. Indeed, their presolver and heuristics were always solving our problem without even performing the branch-and-bound algorithm.
That is why additional tests may be required on different MIP solvers to validate the advantages of reducing as best the number of steps along the guide.

% SL1M => L'aspect geometrique est super intéressant. Les observations et actions de LEAS ne lui permettaient pas d'avoir assez d'impact dessus. Ca pourrait être de bonnes idées pour plus tard, mais après SL1M en général j'y crois pas trop.
The relaxed formulation SL1M (Section \ref{sub:mip:sl1m} raises a very complex combinatorial and geometric problem.
Our steering method did not have enough control over the variables that compose it. That is why it could be interesting to investigate what additional actions could be performed to help in solving this problem. In particular, directly letting the RL agent select the suitable surfaces for each step could be an interesting idea.


% ====== Perspectives. Une thèse peut être considérée comme le début d’un processus de recherche ; il y a toujours des choses à compléter, et vous ou un autre chercheur compléterez les travaux. Dites quelles sont les orientations intéressantes qui se dégagent et pourront être approfondies lors de recherches ultérieures.

\hfill \break

\noindent\textbf{Perspectives.}\\

% J'aurai bien aimé essayer des short horizon contact planners. Mais on en avait pas dans l'equipe au moment de ma thèse. Le MIP en mode MPC j'y crois pas trop, trop long. Donc j'aimerai bien tester avec juste une heuristique de raibert par exemple.
Following our results, we believe our steering method could naturally be extended in two manners.
First, we mainly focused on humanoid robot locomotion, but our method could be easily applied to quadruped robots.
Second, all three contact planners used were long-horizon planners. Yet, it could be interesting to test our approach on short-horizon planners that may be subject to different feasibility criteria.


% Apprendre directement des planners ou controllers à suivre dans le pipeline sont necessaires pour correctement approximer leur faisabilité, ainsi que compléter la notion de traversabilité.
Overall, we believe that path feasibility should be learned directly from experience with the robot itself.
% Mais ça peut être très long à entrainer. Ici nos contact planners étaient plutot rapide, donc ça allait, mais pour approximer tout le pipeline, ça sera sans doute très long d'obtenir les data.
In this thesis, we focused on the path feasibility by a given contact planner. Extending this concept to the whole-body movement could get us closer to our goal of a fast and safe solution for legged robot locomotion in complex environments.

% Finalement avec toutes les recherches que je vois sur le ML/RL, je me pose la question de savoir comment le RL devrait être utilisé. On a du mal ici à savoir pourquoi il a adopté telle ou telle strategie, et pourquoi ça a marché avec le contact planner. Et pour améliorer les choses plus tard, il faudrait qu'on puisse savoir ce pourquoi afin de faire avancer la recherche.
Finally, we would like to add a final word on the place of Reinforcement Learning within the past years.
When training such an RL agent subject to complex or in our case unknown feasibility criteria, it is not an easy task to comprehend its behavior in a given situation.
Just as us humans, we can difficulty explain why we behave in a certain way. However, comprehending the reasons can help us better guide our future choices.
\textcolor{blue}{J'ai essayé de faire un truc sur une reflexion que j'ai eu, à voir si c'est idiot ou pas?}

% Après avoir entrainé un agent, c'est pas fini. Il faut savoir pourquoi il fait ça.

\end{document}
